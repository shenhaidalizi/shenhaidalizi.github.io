---
layout:     post
title:      [深度学习]
subtitle:   [第五章笔记]
date:       [2023-03-17]
author:     Siyuan Zhou
header-img: img/post-bg-article.jpg
catalog: true
tags:
    - Artificial Intelligence
---

 浅层学习：分段学习

![img](https://img-blog.csdnimg.cn/65c7d431cb4242d8990d316c813a6b8b.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

深度学习是**端到端学习**，通过**卷积**、**池化**和**误差反向传播**等手段，进行特征学习。

![img](https://img-blog.csdnimg.cn/e992b3f5182e429a9d6695d1ee8e78f0.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

深度学习所得模型可视为一个复杂函数，非线性变换与映射的过程就是从**像素点**到**语义**之间的转换。

### 刻画神经元功能的数学模型

![img](https://img-blog.csdnimg.cn/edd4b548dbdc4c6bac71d58d74ff1cd0.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

常用激活函数：对输入信息进行非线性变换

![img](https://img-blog.csdnimg.cn/26355bc4766d48e9ba8685ed0a8f11c7.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

# 前馈神经网络

各个神经元接受前一级的输入，并输出到下一级，模型中没有反馈。

层与层之间通过全连接进行链接，即两个相邻层之间的神经元完全成对连接，但层内的神经元不相互连接。

![img](https://img-blog.csdnimg.cn/605517b2a68248e392f458651e74cfb2.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)



感知机网络：

- 是一种特殊的前馈神经网络；
- 无隐藏层，只有输入层/输出层；
- 无法拟合复杂的数据；

![img](https://img-blog.csdnimg.cn/4f1637583e0844a3baf604168bb17c4a.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

## 优化网络参数

从标注数据出发，优化模型参数：

![img](https://img-blog.csdnimg.cn/e8ed55b15cc348e196e0c4983ccb9540.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

![img](https://img-blog.csdnimg.cn/280f2ba4054b474c9c4bb050c91369e9.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

![img](https://img-blog.csdnimg.cn/cb3dd34cbc1c4f19b42f43ab533bd36e.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

# 参数优化

## 梯度下降

梯度下降算法是一种是的损失最小化的方法。一元变量所构成函数f在x处梯度为：

![img](https://img-blog.csdnimg.cn/0136e97538374cada4b2b7ee96f6b0d1.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

- 在多元函数中，梯度是对每一变量所求导数组成的向量；
- 梯度的反方向是函数值下降最快的方向

![img](https://img-blog.csdnimg.cn/a8337fadc7cb4b8facbac01c36340e73.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

## 误差反向传播

- BP算法是一种将输出层误差反向传播给隐藏层进行参数更新的方法；
- 将误差从后向前传递，将误差分摊给各层所有单元，从而获得各层单元所产生的误差，进而一句这个误差来让各层单元负起各自责任、修正各单元参数；

![img](https://img-blog.csdnimg.cn/af026499beb64a32a2c9621d28adccc6.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

前向传播：

![img](https://img-blog.csdnimg.cn/d17eda5666324622823013d892337d5f.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

反向传播：

1. 梯度计算；
2. 更新参数；

![img](https://img-blog.csdnimg.cn/ed5ca79e3dae4cdda0f250d842acf10b.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)



# 卷积神经网络

![img](https://img-blog.csdnimg.cn/b79fbd2532fd4626ab6115234336f77d.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

卷积操作：图像经过特定矩阵滤波后，所得到的卷积结果可认为是保留了像素点所构成的特定空间分布模式。

非线性映射：在对原始图像做卷积操作后，可使用Relu激活函数对卷积函数对卷积后结果进行处理。

池化操作：

- 对输入的特征图进行下采样，以获得最主要信息；
- 常用的池化操作：最大池化、平均池化；

全连接层：特征图转换成向量；

分类层：输出识别分类的置信度值；



## 自然语言理解

- 在基于规则和统计的自然语言传统方法中，将单词作为独立符号；
- 在向量空间中，一个单词按照其在文档中出现的有无，被表示为如下向量（按照字典序），这种表示方法称为One-hot向量；

缺点：

- 维数灾难的困扰；
- 无法刻画词与词之间的相似性：任意两个词之间都是孤立的；

词向量：

- One-hot表达与单词分布无关；
- 通过深度学习方法，将单词表征为K维实数值向量。这样，把文本内容分析简化为K维向量空间中的向量运算，而向量空间上的相似度可以用来表示文本语义上的相似。用深度学习算法生成每个单词的向量表达所有单词的向量表达组成了一个“词向量空间”；

![img](https://img-blog.csdnimg.cn/503318dec2bc43e1a7d474522e4d3414.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

![img](https://img-blog.csdnimg.cn/9384297088c542eab2749eb2f73971f0.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

##  视觉分析

![img](https://img-blog.csdnimg.cn/b2dec23183674710adb97964217bd7de.png)

![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)
